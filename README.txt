 * 一些爬虫练手的小项目
 # 百度贴吧爬虫(BaiduTieba)
	* 使用正则匹配来得到网页的信息
	* 获取的数据有:帖子标题、作者、发布时间、主要内容
	* 存储在tiebadata.txt文件中(700页)
	* 缺点：爬取速度慢
	* 2018-4-10 16:52

 # 糗事百科爬虫(Qiushibaike)
	* 使用PyQuery来得到网页的信息
	* 获取的数据有：段子、作者、好笑数
	* 存储在qiubai.txt文件中(10页)
	* 缺点：只爬取了文字，没有爬取图片
	* 2018-4-11 16:42
	
 # 豆瓣图书Top250爬虫(DoubanBookTop250)
	* 使用BeautifulSoup来处理网页信息
	* 获取数据有：书名、出版社、评分、评价数、简评
	* 存储在book_top250.txt文件中(10页)
	* 缺点：没有添加序列号
	* 2018-4-12 15:03
	
 # 马云微博爬虫(MayunWeibo)
	* Ajax动态网页爬取,将数据转为json格式处理
	* 获取数据有：微博id、微博预览内容、点赞数、评论数、转发数
	* 存储在mayunweibo.txt文件中(至爬取时的全部微博)
	* 总结：
		1、对照他人的代码写出的；
		2、对json数据的处理方法没有弄清；
		3、只爬取了微博的部分内容，没有将全文与图片一并爬取
	* 2018-4-13 16:45
	
 #  刘强东微博爬虫(LiuqiangdongWeibo)
	* Ajax动态网页爬取
	* 获取的数据有：微博内容、点赞数、评论数、转发数、微博图片
	* 内容存储在liuqiangdong.txt文件中（50页），图片存储在pictures文件夹（未上传）
	*总结：
		1、爬取速度缓慢；
		2、在爬取第149篇微博时，图片爬取出现错误，可该微博没有图片，错误原因不明
		3、在爬取过程中偶会出现json文件错误，猜测可能是服务器反爬故意发送错误数据
	* 2018-4-14 18:34

 # 豆瓣新片排行榜(DoubanNewMovies)
	* 在Linux环境下爬取，使用BeautifulSoup库解析网页
	* 获取的数据有：排行、片名、主演与上映时间、评分、评论数
	* 结果存储在DoubanNewMovies.txt文件与MongoDB数据库中
	* 总结：
		1、对数据库的存储不熟练；
		2、原本爬取猫眼电影失败，遭遇反爬；可之前在Windows系统下爬取成功，具体原因不明
	* 2018-4-17 20：32

 # 百度百科爬虫(BaiduBaike)
	* 在Linux环境下爬取，采取面向对象的方式编程
	* 可以自主输入关键词，爬取你想要的信息
	* 获取的数据有：主题(title)、词根(para)、简介(info)、目录(index)、文本(text)
	* 结果储存在data文件夹下的json文件中
	* 总结：
		1、面向对象的编程方式很适合大型项目 ，项目结构清晰
		2、对使用面向对象的方式编程还不够熟练
		3、在网页解析与数据格式处理方面还很薄弱
		4、没有将项目获得的数据储存在数据库中
	* 2018-4-20 14：10

 # 百度新闻爬虫(BaiduNews)
	* 在Linux环境下爬取，采取面向对象的方式编程
	* 可以自主输入关键词，爬取你想要的新闻
	* 获取数据有：主题、作者(可选)、简介、链接、该新闻总数
	* 结果储存在data文件夹下的txt文件中
	* 总结：
		1、原本想根据链接爬取每条新闻，发现新闻来自不同网站、爬取十分困难
		2、没有讲数据储存在数据库中，不会使用python操作MySQL
	* 2018-4-17 15:32

